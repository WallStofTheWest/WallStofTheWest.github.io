{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "#Import Modules\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import datetime as dt\n",
    "import random\n",
    "from Config import api_key\n",
    "from Config2 import pwd\n",
    "# BDay is business day\n",
    "from pandas.tseries.offsets import BDay\n",
    "import math\n",
    "import time\n",
    "import calendar\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sqlalchemy.orm import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup pymysql and connect to local MySQL workbench\n",
    "pymysql.install_as_MySQLdb() \n",
    "string = f\"mysql://ucbx:{pwd}@stock-data-analysis.ciuxgx1cjbsw.us-east-2.rds.amazonaws.com/stock_data\"\n",
    "engine = create_engine(string)\n",
    "# Establish a connection to the local DB\n",
    "conn = engine.connect()\n",
    "# Import and establish Base for which classes will be constructed\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "Base = declarative_base()\n",
    "# Import modules to declare columns and column data types\n",
    "from sqlalchemy import Column, Integer, String, Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table to hold s&p 500 stock list from Wikipedia\n",
    "# ----------------------------------\n",
    "class sandp_stocks (Base):\n",
    "    __tablename__ = 'sandp_stocks'\n",
    "    symbol = Column(String(10),primary_key=True)\n",
    "    security = Column(String(250))\n",
    "    sec_filing = Column(String(50))\n",
    "    gics_sector = Column(String(250))\n",
    "    gics_sub_industry = Column(String(250))\n",
    "    hq_location = Column(String(250))\n",
    "    date_added = Column(String(10))\n",
    "    cik = Column(Integer)\n",
    "    year_founded = Column(Integer)\n",
    "\n",
    "# Create table to hold s&p 500 stock TIME_SERIES_DAILY_ADJUSTED data\n",
    "# ----------------------------------\n",
    "class stock_daily_adjusted (Base):\n",
    "    __tablename__ = 'stock_daily_adjusted'\n",
    "    symbol = Column(String(10),primary_key=True)\n",
    "    date = Column(String(10),primary_key=True)\n",
    "    open = Column(Float)\n",
    "    high = Column(Float)\n",
    "    close = Column(Float)\n",
    "    adjusted_close = Column(Float)\n",
    "    volume = Column(Float)\n",
    "    divident_amount = Column(Float)\n",
    "    split_coeff = Column(Float)\n",
    "\n",
    "# # Create table to hold s&p 500 stock year on year return (Jan to Dec)\n",
    "# # ----------------------------------\n",
    "# class sandp_stocks (Base):\n",
    "#     __tablename__ = 'stock_yony_return'\n",
    "#     symbol = Column(String(10),primary_key=True)\n",
    "#     gics_sector = Column(String(100))\n",
    "#     2019 = Column(Float)\n",
    "#     2018 = Column(Float)\n",
    "#     2017 = Column(Float)\n",
    "#     2016 = Column(Float)\n",
    "#     2015 = Column(Float)\n",
    "#     2014 = Column(Float)\n",
    "#     2013 = Column(Float)\n",
    "#     2012 = Column(Float)\n",
    "#     2011 = Column(Float)\n",
    "#     2010 = Column(Float)\n",
    "#     2009 = Column(Float)\n",
    "#     2008 = Column(Float)\n",
    "#     2007 = Column(Float)\n",
    "#     2006 = Column(Float)\n",
    "#     2005 = Column(Float)\n",
    "#     2004 = Column(Float)\n",
    "#     2003 = Column(Float)\n",
    "#     2002 = Column(Float)\n",
    "#     2001 = Column(Float)\n",
    "#     2000 = Column(Float)\n",
    "#     1999 = Column(Float)\n",
    "#     1998 = Column(Float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create both the company_diversity_m_f and company_diversity_race tables within the database\n",
    "Base.metadata.create_all(conn)\n",
    "# confirming that tables got created in the DB\n",
    "engine.table_names()\n",
    "# Create a session that binds to the engine to enable insert of data\n",
    "session = Session(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>security</th>\n",
       "      <th>symbol</th>\n",
       "      <th>sec_filing</th>\n",
       "      <th>gics_sector</th>\n",
       "      <th>gics_sub_industry</th>\n",
       "      <th>hq_location</th>\n",
       "      <th>date_added</th>\n",
       "      <th>cik</th>\n",
       "      <th>year_founded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>Xylem Inc.</td>\n",
       "      <td>XYL</td>\n",
       "      <td>reports</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Machinery</td>\n",
       "      <td>White Plains, New York</td>\n",
       "      <td>2011-11-01</td>\n",
       "      <td>0001524472</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>Yum! Brands Inc</td>\n",
       "      <td>YUM</td>\n",
       "      <td>reports</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Louisville, Kentucky</td>\n",
       "      <td>1997-10-06</td>\n",
       "      <td>0001041061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>Zimmer Biomet Holdings</td>\n",
       "      <td>ZBH</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>Warsaw, Indiana</td>\n",
       "      <td>2001-08-07</td>\n",
       "      <td>0001136869</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>Zions Bancorp</td>\n",
       "      <td>ZION</td>\n",
       "      <td>reports</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Regional Banks</td>\n",
       "      <td>Salt Lake City, Utah</td>\n",
       "      <td>2001-06-22</td>\n",
       "      <td>0000109380</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>Zoetis</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>Florham Park, New Jersey</td>\n",
       "      <td>2013-06-21</td>\n",
       "      <td>0001555280</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   security symbol sec_filing             gics_sector  \\\n",
       "501              Xylem Inc.    XYL    reports             Industrials   \n",
       "502         Yum! Brands Inc    YUM    reports  Consumer Discretionary   \n",
       "503  Zimmer Biomet Holdings    ZBH    reports             Health Care   \n",
       "504           Zions Bancorp   ZION    reports              Financials   \n",
       "505                  Zoetis    ZTS    reports             Health Care   \n",
       "\n",
       "         gics_sub_industry               hq_location  date_added         cik  \\\n",
       "501   Industrial Machinery    White Plains, New York  2011-11-01  0001524472   \n",
       "502            Restaurants      Louisville, Kentucky  1997-10-06  0001041061   \n",
       "503  Health Care Equipment           Warsaw, Indiana  2001-08-07  0001136869   \n",
       "504         Regional Banks      Salt Lake City, Utah  2001-06-22  0000109380   \n",
       "505        Pharmaceuticals  Florham Park, New Jersey  2013-06-21  0001555280   \n",
       "\n",
       "    year_founded  \n",
       "501          NaN  \n",
       "502          NaN  \n",
       "503          NaN  \n",
       "504          NaN  \n",
       "505          NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtain list of S&P 500 stocks from Wikipedia into a DataFrame\n",
    "site1 = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "table2 = pd.read_html(site1)\n",
    "df_wiki1 = table2[0]\n",
    "df_wiki1.columns = df_wiki1.iloc[0]\n",
    "# Dropping the column names which were added to the dataframe as rows\n",
    "df_wiki1 = df_wiki1.drop(df_wiki1.index[0])\n",
    "# Setting column names for the dataframe\n",
    "df_wiki1.columns = ['security', 'symbol', 'sec_filing', 'gics_sector','gics_sub_industry','hq_location','date_added', 'cik', 'year_founded']\n",
    "df_wiki1.to_sql(name='sandp_stocks', con=engine, if_exists='replace', index=True)\n",
    "df_wiki1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deifie elements needed to construct the alphavantage URL to get stock data\n",
    "base_url = 'https://www.alphavantage.co/query?'\n",
    "function_type = 'TIME_SERIES_DAILY_ADJUSTED'\n",
    "outputsize = 'full'\n",
    "category = f\"function={function_type}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MMM',\n",
       " 'ABT',\n",
       " 'ABBV',\n",
       " 'ABMD',\n",
       " 'ACN',\n",
       " 'ATVI',\n",
       " 'ADBE',\n",
       " 'AMD',\n",
       " 'AAP',\n",
       " 'AES',\n",
       " 'AMG',\n",
       " 'AFL',\n",
       " 'A',\n",
       " 'APD',\n",
       " 'AKAM',\n",
       " 'ALK',\n",
       " 'ALB',\n",
       " 'ARE',\n",
       " 'ALXN',\n",
       " 'ALGN',\n",
       " 'ALLE',\n",
       " 'AGN',\n",
       " 'ADS',\n",
       " 'LNT',\n",
       " 'ALL',\n",
       " 'GOOGL',\n",
       " 'GOOG',\n",
       " 'MO',\n",
       " 'AMZN',\n",
       " 'AEE',\n",
       " 'AAL',\n",
       " 'AEP',\n",
       " 'AXP',\n",
       " 'AIG',\n",
       " 'AMT',\n",
       " 'AWK',\n",
       " 'AMP',\n",
       " 'ABC',\n",
       " 'AME',\n",
       " 'AMGN',\n",
       " 'APH',\n",
       " 'APC',\n",
       " 'ADI',\n",
       " 'ANSS',\n",
       " 'ANTM',\n",
       " 'AON',\n",
       " 'AOS',\n",
       " 'APA',\n",
       " 'AIV',\n",
       " 'AAPL',\n",
       " 'AMAT',\n",
       " 'APTV',\n",
       " 'ADM',\n",
       " 'ARNC',\n",
       " 'ANET',\n",
       " 'AJG',\n",
       " 'AIZ',\n",
       " 'ATO',\n",
       " 'T',\n",
       " 'ADSK',\n",
       " 'ADP',\n",
       " 'AZO',\n",
       " 'AVB',\n",
       " 'AVY',\n",
       " 'BHGE',\n",
       " 'BLL',\n",
       " 'BAC',\n",
       " 'BK',\n",
       " 'BAX',\n",
       " 'BBT',\n",
       " 'BDX',\n",
       " 'BRK-B',\n",
       " 'BBY',\n",
       " 'BIIB',\n",
       " 'BLK',\n",
       " 'HRB',\n",
       " 'BA',\n",
       " 'BKNG',\n",
       " 'BWA',\n",
       " 'BXP',\n",
       " 'BSX',\n",
       " 'BHF',\n",
       " 'BMY',\n",
       " 'AVGO',\n",
       " 'BR',\n",
       " 'BF-B',\n",
       " 'CHRW',\n",
       " 'COG',\n",
       " 'CDNS',\n",
       " 'CPB',\n",
       " 'COF',\n",
       " 'CPRI',\n",
       " 'CAH',\n",
       " 'KMX',\n",
       " 'CCL',\n",
       " 'CAT',\n",
       " 'CBOE',\n",
       " 'CBRE',\n",
       " 'CBS',\n",
       " 'CE',\n",
       " 'CELG',\n",
       " 'CNC',\n",
       " 'CNP',\n",
       " 'CTL',\n",
       " 'CERN',\n",
       " 'CF',\n",
       " 'SCHW',\n",
       " 'CHTR',\n",
       " 'CVX',\n",
       " 'CMG',\n",
       " 'CB',\n",
       " 'CHD',\n",
       " 'CI',\n",
       " 'XEC',\n",
       " 'CINF',\n",
       " 'CTAS',\n",
       " 'CSCO',\n",
       " 'C',\n",
       " 'CFG',\n",
       " 'CTXS',\n",
       " 'CLX',\n",
       " 'CME',\n",
       " 'CMS',\n",
       " 'KO',\n",
       " 'CTSH',\n",
       " 'CL',\n",
       " 'CMCSA',\n",
       " 'CMA',\n",
       " 'CAG',\n",
       " 'CXO',\n",
       " 'COP',\n",
       " 'ED',\n",
       " 'STZ',\n",
       " 'COO',\n",
       " 'CPRT',\n",
       " 'GLW',\n",
       " 'COST',\n",
       " 'COTY',\n",
       " 'CCI',\n",
       " 'CSX',\n",
       " 'CMI',\n",
       " 'CVS',\n",
       " 'DHI',\n",
       " 'DHR',\n",
       " 'DRI',\n",
       " 'DVA',\n",
       " 'DE',\n",
       " 'DAL',\n",
       " 'XRAY',\n",
       " 'DVN',\n",
       " 'FANG',\n",
       " 'DLR',\n",
       " 'DFS',\n",
       " 'DISCA',\n",
       " 'DISCK',\n",
       " 'DISH',\n",
       " 'DG',\n",
       " 'DLTR',\n",
       " 'D',\n",
       " 'DOV',\n",
       " 'DWDP',\n",
       " 'DTE',\n",
       " 'DRE',\n",
       " 'DUK',\n",
       " 'DXC',\n",
       " 'ETFC',\n",
       " 'EMN',\n",
       " 'ETN',\n",
       " 'EBAY',\n",
       " 'ECL',\n",
       " 'EIX',\n",
       " 'EW',\n",
       " 'EA',\n",
       " 'EMR',\n",
       " 'ETR',\n",
       " 'EOG',\n",
       " 'EFX',\n",
       " 'EQIX',\n",
       " 'EQR',\n",
       " 'ESS',\n",
       " 'EL',\n",
       " 'EVRG',\n",
       " 'ES',\n",
       " 'RE',\n",
       " 'EXC',\n",
       " 'EXPE',\n",
       " 'EXPD',\n",
       " 'EXR',\n",
       " 'XOM',\n",
       " 'FFIV',\n",
       " 'FB',\n",
       " 'FAST',\n",
       " 'FRT',\n",
       " 'FDX',\n",
       " 'FIS',\n",
       " 'FITB',\n",
       " 'FE',\n",
       " 'FRC',\n",
       " 'FISV',\n",
       " 'FLT',\n",
       " 'FLIR',\n",
       " 'FLS',\n",
       " 'FLR',\n",
       " 'FMC',\n",
       " 'FL',\n",
       " 'F',\n",
       " 'FTNT',\n",
       " 'FTV',\n",
       " 'FBHS',\n",
       " 'BEN',\n",
       " 'FCX',\n",
       " 'GPS',\n",
       " 'GRMN',\n",
       " 'IT',\n",
       " 'GD',\n",
       " 'GE',\n",
       " 'GIS',\n",
       " 'GM',\n",
       " 'GPC',\n",
       " 'GILD',\n",
       " 'GPN',\n",
       " 'GS',\n",
       " 'GT',\n",
       " 'GWW',\n",
       " 'HAL',\n",
       " 'HBI',\n",
       " 'HOG',\n",
       " 'HRS',\n",
       " 'HIG',\n",
       " 'HAS',\n",
       " 'HCA',\n",
       " 'HCP',\n",
       " 'HP',\n",
       " 'HSIC',\n",
       " 'HSY',\n",
       " 'HES',\n",
       " 'HPE',\n",
       " 'HLT',\n",
       " 'HFC',\n",
       " 'HOLX',\n",
       " 'HD',\n",
       " 'HON',\n",
       " 'HRL',\n",
       " 'HST',\n",
       " 'HPQ',\n",
       " 'HUM',\n",
       " 'HBAN',\n",
       " 'HII',\n",
       " 'IDXX',\n",
       " 'INFO',\n",
       " 'ITW',\n",
       " 'ILMN',\n",
       " 'IR',\n",
       " 'INTC',\n",
       " 'ICE',\n",
       " 'IBM',\n",
       " 'INCY',\n",
       " 'IP',\n",
       " 'IPG',\n",
       " 'IFF',\n",
       " 'INTU',\n",
       " 'ISRG',\n",
       " 'IVZ',\n",
       " 'IPGP',\n",
       " 'IQV',\n",
       " 'IRM',\n",
       " 'JKHY',\n",
       " 'JEC',\n",
       " 'JBHT',\n",
       " 'JEF',\n",
       " 'SJM',\n",
       " 'JNJ',\n",
       " 'JCI',\n",
       " 'JPM',\n",
       " 'JNPR',\n",
       " 'KSU',\n",
       " 'K',\n",
       " 'KEY',\n",
       " 'KEYS',\n",
       " 'KMB',\n",
       " 'KIM',\n",
       " 'KMI',\n",
       " 'KLAC',\n",
       " 'KSS',\n",
       " 'KHC',\n",
       " 'KR',\n",
       " 'LB',\n",
       " 'LLL',\n",
       " 'LH',\n",
       " 'LRCX',\n",
       " 'LW',\n",
       " 'LEG',\n",
       " 'LEN',\n",
       " 'LLY',\n",
       " 'LNC',\n",
       " 'LIN',\n",
       " 'LKQ',\n",
       " 'LMT',\n",
       " 'L',\n",
       " 'LOW',\n",
       " 'LYB',\n",
       " 'MTB',\n",
       " 'MAC',\n",
       " 'M',\n",
       " 'MRO',\n",
       " 'MPC',\n",
       " 'MAR',\n",
       " 'MMC',\n",
       " 'MLM',\n",
       " 'MAS',\n",
       " 'MA',\n",
       " 'MAT',\n",
       " 'MKC',\n",
       " 'MXIM',\n",
       " 'MCD',\n",
       " 'MCK',\n",
       " 'MDT',\n",
       " 'MRK',\n",
       " 'MET',\n",
       " 'MTD',\n",
       " 'MGM',\n",
       " 'MCHP',\n",
       " 'MU',\n",
       " 'MSFT',\n",
       " 'MAA',\n",
       " 'MHK',\n",
       " 'TAP',\n",
       " 'MDLZ',\n",
       " 'MNST',\n",
       " 'MCO',\n",
       " 'MS',\n",
       " 'MOS',\n",
       " 'MSI',\n",
       " 'MSCI',\n",
       " 'MYL',\n",
       " 'NDAQ',\n",
       " 'NOV',\n",
       " 'NKTR',\n",
       " 'NTAP',\n",
       " 'NFLX',\n",
       " 'NWL',\n",
       " 'NEM',\n",
       " 'NWSA',\n",
       " 'NWS',\n",
       " 'NEE',\n",
       " 'NLSN',\n",
       " 'NKE',\n",
       " 'NI',\n",
       " 'NBL',\n",
       " 'JWN',\n",
       " 'NSC',\n",
       " 'NTRS',\n",
       " 'NOC',\n",
       " 'NCLH',\n",
       " 'NRG',\n",
       " 'NUE',\n",
       " 'NVDA',\n",
       " 'ORLY',\n",
       " 'OXY',\n",
       " 'OMC',\n",
       " 'OKE',\n",
       " 'ORCL',\n",
       " 'PCAR',\n",
       " 'PKG',\n",
       " 'PH',\n",
       " 'PAYX',\n",
       " 'PYPL',\n",
       " 'PNR',\n",
       " 'PBCT',\n",
       " 'PEP',\n",
       " 'PKI',\n",
       " 'PRGO',\n",
       " 'PFE',\n",
       " 'PM',\n",
       " 'PSX',\n",
       " 'PNW',\n",
       " 'PXD',\n",
       " 'PNC',\n",
       " 'RL',\n",
       " 'PPG',\n",
       " 'PPL',\n",
       " 'PFG',\n",
       " 'PG',\n",
       " 'PGR',\n",
       " 'PLD',\n",
       " 'PRU',\n",
       " 'PEG',\n",
       " 'PSA',\n",
       " 'PHM',\n",
       " 'PVH',\n",
       " 'QRVO',\n",
       " 'PWR',\n",
       " 'QCOM',\n",
       " 'DGX',\n",
       " 'RJF',\n",
       " 'RTN',\n",
       " 'O',\n",
       " 'RHT',\n",
       " 'REG',\n",
       " 'REGN',\n",
       " 'RF',\n",
       " 'RSG',\n",
       " 'RMD',\n",
       " 'RHI',\n",
       " 'ROK',\n",
       " 'ROL',\n",
       " 'ROP',\n",
       " 'ROST',\n",
       " 'RCL',\n",
       " 'CRM',\n",
       " 'SBAC',\n",
       " 'SLB',\n",
       " 'STX',\n",
       " 'SEE',\n",
       " 'SRE',\n",
       " 'SHW',\n",
       " 'SPG',\n",
       " 'SWKS',\n",
       " 'SLG',\n",
       " 'SNA',\n",
       " 'SO',\n",
       " 'LUV',\n",
       " 'SPGI',\n",
       " 'SWK',\n",
       " 'SBUX',\n",
       " 'STT',\n",
       " 'SYK',\n",
       " 'STI',\n",
       " 'SIVB',\n",
       " 'SYMC',\n",
       " 'SYF',\n",
       " 'SNPS',\n",
       " 'SYY',\n",
       " 'TROW',\n",
       " 'TTWO',\n",
       " 'TPR',\n",
       " 'TGT',\n",
       " 'TEL',\n",
       " 'FTI',\n",
       " 'TFX',\n",
       " 'TXN',\n",
       " 'TXT',\n",
       " 'TMO',\n",
       " 'TIF',\n",
       " 'TWTR',\n",
       " 'TJX',\n",
       " 'TMK',\n",
       " 'TSS',\n",
       " 'TSCO',\n",
       " 'TDG',\n",
       " 'TRV',\n",
       " 'TRIP',\n",
       " 'FOXA',\n",
       " 'FOX',\n",
       " 'TSN',\n",
       " 'UDR',\n",
       " 'ULTA',\n",
       " 'USB',\n",
       " 'UAA',\n",
       " 'UA',\n",
       " 'UNP',\n",
       " 'UAL',\n",
       " 'UNH',\n",
       " 'UPS',\n",
       " 'URI',\n",
       " 'UTX',\n",
       " 'UHS',\n",
       " 'UNM',\n",
       " 'VFC',\n",
       " 'VLO',\n",
       " 'VAR',\n",
       " 'VTR',\n",
       " 'VRSN',\n",
       " 'VRSK',\n",
       " 'VZ',\n",
       " 'VRTX',\n",
       " 'VIAB',\n",
       " 'V',\n",
       " 'VNO',\n",
       " 'VMC',\n",
       " 'WMT',\n",
       " 'WBA',\n",
       " 'DIS',\n",
       " 'WM',\n",
       " 'WAT',\n",
       " 'WEC',\n",
       " 'WCG',\n",
       " 'WFC',\n",
       " 'WELL',\n",
       " 'WDC',\n",
       " 'WU',\n",
       " 'WRK',\n",
       " 'WY',\n",
       " 'WHR',\n",
       " 'WMB',\n",
       " 'WLTW',\n",
       " 'WYNN',\n",
       " 'XEL',\n",
       " 'XRX',\n",
       " 'XLNX',\n",
       " 'XYL',\n",
       " 'YUM',\n",
       " 'ZBH',\n",
       " 'ZION',\n",
       " 'ZTS']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock = pd.read_sql('select distinct(symbol) from sandp_stocks;', con=conn)\n",
    "stock_list = stock['symbol'].tolist()\n",
    "stock_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the variables to hold data pulled from alphavantage site\n",
    "open = []\n",
    "high = []\n",
    "low = []\n",
    "close = []\n",
    "adjusted_close = []\n",
    "volume = []\n",
    "divident_amount = []\n",
    "split_coeff = []\n",
    "dates = []\n",
    "data_dict = {}\n",
    "# create a list of all column names for the dataframe that we intend to create\n",
    "#table = [dates, open, high, low, close, adjusted_close, volume, divident_amount, split_coeff ]\n",
    "# create dataframe & transpose the dataframe to get desired columns\n",
    "#df = pd.DataFrame(table).transpose()\n",
    "# Define column names\n",
    "#df.columns = ['date','open', 'high', 'low', 'close', 'adjusted_close', 'volume', 'divident_amount', 'split_coeff']\n",
    "# Create a new column named Symbol\n",
    "#df['symbol']= ''\n",
    "# Create the final dataframe structure that we plan to use which includes the symbol column as well and re-order so symbol is first column\n",
    "#merged_df = df[['symbol','date','open', 'high', 'low', 'close', 'adjusted_close', 'volume', 'divident_amount', 'split_coeff']]\n",
    "#print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CE', 'FLT', 'LOW', 'REGN', 'ZTS']\n",
      "https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol=CE&outputsize=full&apikey=LE5P4Z3N42YZAG0M\n",
      "https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol=FLT&outputsize=full&apikey=LE5P4Z3N42YZAG0M\n",
      "https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol=LOW&outputsize=full&apikey=LE5P4Z3N42YZAG0M\n",
      "https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol=REGN&outputsize=full&apikey=LE5P4Z3N42YZAG0M\n",
      "https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol=ZTS&outputsize=full&apikey=LE5P4Z3N42YZAG0M\n"
     ]
    }
   ],
   "source": [
    "# define list of stocks to fetch data from alphavantage site\n",
    "#stock_list = ['GOOG','T','DIS','AMZN','BBY','EBAY','CLX','KO','COST','CVX','XOM','HAL','AXP','BRK-B','JPM','ABT','CI','JNJ','BA','CAT','FDX','AAPL','MA','TXN','IP','NUE','PPG','AVB','ESS','IRM','LNT','EVRG','NRG']\n",
    "#stock_list1 = ['LUV', 'SPGI', 'SWK', 'SBUX', 'STT', 'SYK', 'STI', 'SIVB', 'SYMC', 'SYF', 'SNPS', 'SYY', 'TROW', 'TTWO', 'TPR', 'TGT', 'TEL', 'FTI', 'TFX', 'TXN', 'TXT', 'TMO', 'TIF', 'TWTR', 'TJX', 'TMK', 'TSS', 'TSCO', 'TDG', 'TRV', 'TRIP', 'FOXA', 'FOX', 'TSN', 'UDR', 'ULTA', 'USB', 'UAA', 'UA', 'UNP', 'UAL', 'UNH', 'UPS', 'URI', 'UTX', 'UHS', 'UNM', 'VFC', 'VLO', 'VAR', 'VTR', 'VRSN', 'VRSK', 'VZ', 'VRTX', 'VIAB', 'V', 'VNO', 'VMC', 'WMT', 'WBA', 'DIS', 'WM', 'WAT', 'WEC', 'WCG', 'WFC', 'WELL', 'WDC', 'WU', 'WRK', 'WY', 'WHR', 'WMB', 'WLTW', 'WYNN', 'XEL', 'XRX', 'XLNX', 'XYL', 'YUM', 'ZBH', 'ZION']\n",
    "#stock_list1 = stock_list[400:504]\n",
    "#stock_list = ['CE','FLT','LOW','REGN','ZTS']\n",
    "print(stock_list)\n",
    "# for each stock obtain TIME_SERIES_DAILY_ADJUSTED data for last 20 years\n",
    "for stock in stock_list:\n",
    "    # final URl to be used\n",
    "    final_url2 = f\"{base_url}{category}&symbol={stock}&outputsize={outputsize}&apikey={api_key}\"\n",
    "    print(final_url2)\n",
    "    response = requests.get(final_url2)\n",
    "    #converting api response to JSON data\n",
    "    response_json = response.json()\n",
    "    response_json.keys()\n",
    "    # defining the variables to hold data pulled from alphavantage site\n",
    "    date_list = []\n",
    "    open = []\n",
    "    high = []\n",
    "    low = []\n",
    "    close = []\n",
    "    adjusted_close = []\n",
    "    volume = []\n",
    "    divident_amount = []\n",
    "    split_coeff = []\n",
    "    data_dict = {}\n",
    "    # obtain list of all dates for which data is available from alphavantage for each stock\n",
    "    dates = response_json['Time Series (Daily)'].keys()\n",
    "    #print(response.status_code)\n",
    "    for date in dates:\n",
    "        if response.status_code == 200:\n",
    "            # ensuring we catch any exceptions using a try catch for bad data retuned from API call while status of 200 is sent\n",
    "            try:\n",
    "                # extracting data from the json object and adding it to respective lists \n",
    "                date_list.append(date)\n",
    "                open.append(response_json['Time Series (Daily)'][date]['1. open'])\n",
    "                high.append(response_json['Time Series (Daily)'][date]['2. high'])\n",
    "                low.append(response_json['Time Series (Daily)'][date]['3. low'])\n",
    "                close.append(response_json['Time Series (Daily)'][date]['4. close'])\n",
    "                adjusted_close.append(response_json['Time Series (Daily)'][date]['5. adjusted close'])\n",
    "                volume.append(response_json['Time Series (Daily)'][date]['6. volume'])\n",
    "                divident_amount.append(response_json['Time Series (Daily)'][date]['7. dividend amount'])\n",
    "                split_coeff.append(response_json['Time Series (Daily)'][date]['8. split coefficient'])\n",
    "            #handling an exception bad data retuned from API call while status of 200 is sent\n",
    "            except:\n",
    "                print('Skipping an entry due to lack of stock data\\n')\n",
    "            #catching a bad response from API anything other than status 200 and skipping that data\n",
    "        else:\n",
    "            print(\"Hmmm, are you sure there is a stock with that ticker?\\n\")\n",
    "    # Create a dictionary holding all data gathered for one stock\n",
    "    data_dict = {\n",
    "                'symbol':stock,\n",
    "                'date':date_list,\n",
    "                'open': open,\n",
    "                'high': high,\n",
    "                'low': low,\n",
    "                'close': close,\n",
    "                'adjusted_close': adjusted_close ,\n",
    "                'volume':volume,\n",
    "                'divident_amount':divident_amount,\n",
    "                'split_coeff':split_coeff\n",
    "                }\n",
    "    # creating a dataframe from the dictionry\n",
    "    temp_df = pd.DataFrame.from_dict(data_dict)\n",
    "    temp_df.to_sql(name='stock_daily_adjusted', con=engine, if_exists='append', index=False)\n",
    "    #temp_df['yony'] = temp_df['date'].apply(lambda x: yonycalc(x))\n",
    "    # merging the temp dataframe data into the datafram structure created earlier to hold the final data\n",
    "    #merged_df = merged_df.append(temp_df,ignore_index=True)\n",
    "    # sleep for 13 seconds after each stock's data extraction to avoid going over 5 API calls per min to alphavantage\n",
    "    time.sleep(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>divident_amount</th>\n",
       "      <th>split_coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2019-02-15</td>\n",
       "      <td>206.4600</td>\n",
       "      <td>208.9700</td>\n",
       "      <td>206.0000</td>\n",
       "      <td>208.8600</td>\n",
       "      <td>208.8600</td>\n",
       "      <td>2000278</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>206.5900</td>\n",
       "      <td>207.1200</td>\n",
       "      <td>204.0500</td>\n",
       "      <td>204.9300</td>\n",
       "      <td>204.9300</td>\n",
       "      <td>2229753</td>\n",
       "      <td>1.4400</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>207.0900</td>\n",
       "      <td>210.4000</td>\n",
       "      <td>206.5900</td>\n",
       "      <td>209.7200</td>\n",
       "      <td>208.2566</td>\n",
       "      <td>2967332</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>202.8700</td>\n",
       "      <td>206.7900</td>\n",
       "      <td>202.1900</td>\n",
       "      <td>206.5700</td>\n",
       "      <td>205.1286</td>\n",
       "      <td>2622973</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MMM</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>200.9300</td>\n",
       "      <td>201.2000</td>\n",
       "      <td>199.6400</td>\n",
       "      <td>200.9100</td>\n",
       "      <td>199.5081</td>\n",
       "      <td>1513457</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol        date      open      high       low     close adjusted_close  \\\n",
       "0    MMM  2019-02-15  206.4600  208.9700  206.0000  208.8600       208.8600   \n",
       "1    MMM  2019-02-14  206.5900  207.1200  204.0500  204.9300       204.9300   \n",
       "2    MMM  2019-02-13  207.0900  210.4000  206.5900  209.7200       208.2566   \n",
       "3    MMM  2019-02-12  202.8700  206.7900  202.1900  206.5700       205.1286   \n",
       "4    MMM  2019-02-11  200.9300  201.2000  199.6400  200.9100       199.5081   \n",
       "\n",
       "    volume divident_amount split_coeff  \n",
       "0  2000278          0.0000      1.0000  \n",
       "1  2229753          1.4400      1.0000  \n",
       "2  2967332          0.0000      1.0000  \n",
       "3  2622973          0.0000      1.0000  \n",
       "4  1513457          0.0000      1.0000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.read_sql('select * from stock_daily_adjusted;', con=conn)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  symbol       date    open    high     low   close  adjusted_close  volume  \\\n",
      "0    MMM 2019-02-15  208.86  208.86  208.86  208.86          208.86  208.86   \n",
      "\n",
      "   divident_amount  split_coeff  \n",
      "0           208.86       208.86  \n",
      "        symbol       date   open   high    low  close  adjusted_close  volume  \\\n",
      "2362979    ZTS 2013-02-04  31.02  31.02  31.02  31.02           31.02   31.02   \n",
      "2362980    ZTS 2013-02-01  31.01  31.01  31.01  31.01           31.01   31.01   \n",
      "\n",
      "         divident_amount  split_coeff  \n",
      "2362979            31.02        31.02  \n",
      "2362980            31.01        31.01  \n"
     ]
    }
   ],
   "source": [
    "merged_df[\"symbol\"] = merged_df.symbol.astype(str)\n",
    "merged_df[\"date\"] = pd.to_datetime(merged_df[\"date\"])\n",
    "merged_df[\"open\"] = merged_df.close.astype(float)\n",
    "merged_df[\"high\"] = merged_df.close.astype(float)\n",
    "merged_df[\"close\"] = merged_df.close.astype(float)\n",
    "merged_df[\"low\"] = merged_df.close.astype(float)\n",
    "merged_df[\"adjusted_close\"] = merged_df.close.astype(float)\n",
    "merged_df[\"volume\"] = merged_df.close.astype(float)\n",
    "merged_df[\"divident_amount\"] = merged_df.close.astype(float)\n",
    "merged_df[\"split_coeff\"] = merged_df.close.astype(float)\n",
    "#merged_df.dtypes\n",
    "print(merged_df.head(1))\n",
    "print(merged_df.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>2019</th>\n",
       "      <th>2018</th>\n",
       "      <th>2017</th>\n",
       "      <th>2016</th>\n",
       "      <th>2015</th>\n",
       "      <th>2014</th>\n",
       "      <th>2013</th>\n",
       "      <th>2012</th>\n",
       "      <th>2011</th>\n",
       "      <th>...</th>\n",
       "      <th>2007</th>\n",
       "      <th>2006</th>\n",
       "      <th>2005</th>\n",
       "      <th>2004</th>\n",
       "      <th>2003</th>\n",
       "      <th>2002</th>\n",
       "      <th>2001</th>\n",
       "      <th>2000</th>\n",
       "      <th>1999</th>\n",
       "      <th>1998</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [symbol, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 2006, 2005, 2004, 2003, 2002, 2001, 2000, 1999, 1998]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create structure of the final data frame to hold year on year returns data for each stock\n",
    "final_df = pd.DataFrame(columns=[i for i in range(2019, 1997, -1)])\n",
    "final_df.insert(0, 'symbol', 0)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate year on year retunr for each stock\n",
    "# define an empty dictionary\n",
    "#print(stock_list)\n",
    "dictionary = {}\n",
    "for stk in stock_list:\n",
    "    #print(stk)\n",
    "    # filter the merged data frame having stock data by 1 specific stock and create a new stock specific dataframe\n",
    "    stk_df = merged_df.loc[merged_df['symbol'] == stk]\n",
    "    # identify the most recent year and most recent month for which data is available for the specific stock\n",
    "    start_year = stk_df.iloc[[0]]['date'].dt.year.reset_index(drop=True)\n",
    "    start_year = start_year[0]\n",
    "    start_month = stk_df.iloc[[0]]['date'].dt.month.reset_index(drop=True)\n",
    "    start_month = start_month[0]\n",
    "    # identify the oldest year and corresponding oldest month for which data is available for the specific stock\n",
    "    end_year = stk_df.iloc[[-1]]['date'].dt.year.reset_index(drop=True)\n",
    "    end_year = end_year[0]\n",
    "    end_month = stk_df.iloc[[-1]]['date'].dt.month.reset_index(drop=True)\n",
    "    end_month = end_month[0]\n",
    "    # for each year of data calculate the average month on month return for the stock\n",
    "    for year_value in range(start_year, end_year-1, -1):\n",
    "        monmperc_list = []\n",
    "        # for current year (e.g. 2019) skip the current months data as we might not have the entire months data and only start from previous month and also set end month to 0 so we stop at Jan\n",
    "        if year_value == start_year:\n",
    "            # determine the first month so we start iterating from that month\n",
    "            month_start = start_month-1\n",
    "            # for the start month of Jan, consider Jan and dont skip it\n",
    "            if month_start == 0:\n",
    "                month_start = 1\n",
    "            # set month end to 0 so we stop iterating in Jan\n",
    "            month_end = 0\n",
    "        # for earliest year (e.g. 1998) set month end and also set start month to 12 so we start at Dec\n",
    "        elif year_value == end_year:\n",
    "            # set month start to 12 so we start iterating from Dec\n",
    "            month_start = 12\n",
    "            # determing the last month so we stop iterating at that month\n",
    "            month_end = end_month -1\n",
    "            # if end month is Jan, consider Jan and dont skip it\n",
    "            if month_end == 0:\n",
    "                month_end = 1\n",
    "        else:\n",
    "            month_start = 12\n",
    "            month_end = 0\n",
    "        # for each month within a given year, get the first and last working day (ignoring weekends and days that dont have stock data) and calculate the average return\n",
    "        for month_value in range (month_start, month_end, -1):\n",
    "            # obtain the first and last day of a month\n",
    "            month_range = calendar.monthrange(year_value,month_value)\n",
    "            #Identify first day of the month (0 - Mon & 6 is Sunday)\n",
    "            first_date = month_range[0]\n",
    "            # if first day is a Saturday, move 1st date to 3rd of the month (1st - Sat, 2nd - Sun and 3rd - Mon)\n",
    "            if (first_date == 5):\n",
    "                first_date = 3\n",
    "            # if first day is a Sunday, move 1st date to 2nd of the month (1st Sun and 2nd - Mon)\n",
    "            elif (first_date == 6):\n",
    "                first_date = 2\n",
    "            # if first day is NOT a Saturday or Sunday then set 1st date to 1st of that month\n",
    "            else:\n",
    "                first_date = 1\n",
    "            #Create the first day and last day variables in a date format\n",
    "            first_day = f'{year_value}-{month_value}-{first_date}'\n",
    "            last_day = f'{year_value}-{month_value}-{month_range[1]}'\n",
    "            first_day = pd.to_datetime(first_day)\n",
    "            last_day = pd.to_datetime(last_day)\n",
    "            #Filter the dataframe to get data for the 1st day of the month\n",
    "            filter_1 = (stk_df['date'] == first_day) \n",
    "            df_filter_1 = stk_df.loc[filter_1]['close'].astype(float).reset_index(drop=True)\n",
    "            i=1\n",
    "            # pick next business day if for some reason the first date of the month does not have data from alphavantage\n",
    "            while df_filter_1.empty:\n",
    "                next_buss_date = (first_day + BDay(i))\n",
    "                #Filter the dataframe to get data for the new first date of the month that has information from alphavantage\n",
    "                filter_1 = (stk_df['date'] == next_buss_date)\n",
    "                df_filter_1 = stk_df.loc[filter_1]['close'].astype(float).reset_index(drop=True)\n",
    "                i+=1\n",
    "            #Filter the dataframe to get data for the last day of the month\n",
    "            filter_2 = (stk_df['date'] == last_day)\n",
    "            df_filter_2 = stk_df.loc[filter_2]['close'].astype(float).reset_index(drop=True)\n",
    "            # pick previous business day if for some reason the last date of the month does not have data from alphavantage\n",
    "            j=1\n",
    "            while df_filter_2.empty:\n",
    "                prev_buss_date = (last_day - BDay(j))\n",
    "                #Filter the dataframe to get data for the new last date of the month that has information from alphavantage\n",
    "                filter_2 = (stk_df['date'] == prev_buss_date)\n",
    "                df_filter_2 = stk_df.loc[filter_2]['close'].astype(float).reset_index(drop=True)\n",
    "                j+=1\n",
    "            # calculate the average return for the month based of the close price on 1st date and last date of the month\n",
    "            monmperc = ((df_filter_2 - df_filter_1)/ df_filter_1)*100\n",
    "            # add each months return to a list\n",
    "            monmperc_list.append(monmperc)\n",
    "        #Calculate the average retrun across all months of a given year\n",
    "        avg_monmperc = sum(monmperc_list)/len(monmperc_list)\n",
    "        #Add the symbol and its average yearly return for each year\n",
    "        dictionary['symbol'] = stk\n",
    "        dictionary[year_value] = avg_monmperc\n",
    "    # create a temp dataframe from the dictionary created\n",
    "    temp_df = pd.DataFrame.from_dict(dictionary)\n",
    "    # append this temp data frame to the final dataframe structure created earlier\n",
    "    final_df = final_df.append(temp_df,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  symbol       2019      2018      2017      2016      2015      2014  \\\n",
      "0    MMM   4.896570 -1.009762  1.972439  1.577829 -0.644188  2.099564   \n",
      "1    ABT   5.007194  1.897345  2.955102 -1.099629  0.000240  1.934863   \n",
      "2   ABBV -10.019052 -0.590313  3.175781  0.493654 -1.082617  2.625749   \n",
      "3   ABMD  13.263002  3.277295  4.150829  1.927447  8.483528  4.566464   \n",
      "4    ACN   9.218294 -0.520528  2.364408  0.980228  1.074049  1.434426   \n",
      "\n",
      "       2013      2012      2011    ...         2007      2006      2005  \\\n",
      "0  3.691199  0.980436  0.669179    ...     0.791992  0.244259 -0.399397   \n",
      "1  1.356323  1.365399  1.937698    ...     1.129000  1.962463 -1.343881   \n",
      "2  2.779737  1.365399  1.937698    ...     1.129000  1.962463 -1.343881   \n",
      "3  6.311604  0.906423  8.896198    ...     1.678670  4.287823 -2.810915   \n",
      "4  1.451403  1.982922  1.474177    ...     0.274953  2.267602  0.013521   \n",
      "\n",
      "       2004      2003      2002      2001      2000       1999      1998  \n",
      "0  0.009860 -1.682022  0.100353  0.367833  2.367321   1.910351 -2.294297  \n",
      "1 -0.178627  1.101096 -1.629055  0.695523  2.544372  -2.245057  2.913909  \n",
      "2 -0.178627  1.101096 -1.629055  0.695523  2.544372  -2.245057  2.913909  \n",
      "3  5.212298  2.249722 -8.871266 -2.243599  7.322323  15.023372 -1.298750  \n",
      "4 -0.075716  2.022104 -2.275141  9.495909  7.322323  15.023372 -1.298750  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to identify the gics_sector for any stock\n",
    "def find_gics_sector(symbol):\n",
    "    # filter the s&p 500 dataframe by symbol\n",
    "    filter = (df_wiki1['symbol'] == symbol) \n",
    "    # identify and return the gics_sector for the stock\n",
    "    gics_sector = df_wiki1.loc[filter]['gics_sector'].reset_index(drop=True)\n",
    "    return gics_sector\n",
    "\n",
    "# function to identify the gics_sub_industry for any stock\n",
    "def find_gics_sub_industry(symbol):\n",
    "    # filter the s&p 500 dataframe by symbol\n",
    "    filter = (df_wiki1['symbol'] == symbol) \n",
    "    # identify and return the gics_sector for the stock\n",
    "    gics_sub_industry = df_wiki1.loc[filter]['gics_sub_industry'].reset_index(drop=True)\n",
    "    return gics_sub_industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column for gics_sector and identify its value for each symbol\n",
    "final_df['gics_sector'] = final_df['symbol'].apply(lambda y: find_gics_sector(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>gics_sector</th>\n",
       "      <th>2019</th>\n",
       "      <th>2018</th>\n",
       "      <th>2017</th>\n",
       "      <th>2016</th>\n",
       "      <th>2015</th>\n",
       "      <th>2014</th>\n",
       "      <th>2013</th>\n",
       "      <th>2012</th>\n",
       "      <th>...</th>\n",
       "      <th>2007</th>\n",
       "      <th>2006</th>\n",
       "      <th>2005</th>\n",
       "      <th>2004</th>\n",
       "      <th>2003</th>\n",
       "      <th>2002</th>\n",
       "      <th>2001</th>\n",
       "      <th>2000</th>\n",
       "      <th>1999</th>\n",
       "      <th>1998</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>4.896570</td>\n",
       "      <td>-1.009762</td>\n",
       "      <td>1.972439</td>\n",
       "      <td>1.577829</td>\n",
       "      <td>-0.644188</td>\n",
       "      <td>2.099564</td>\n",
       "      <td>3.691199</td>\n",
       "      <td>0.980436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791992</td>\n",
       "      <td>0.244259</td>\n",
       "      <td>-0.399397</td>\n",
       "      <td>0.009860</td>\n",
       "      <td>-1.682022</td>\n",
       "      <td>0.100353</td>\n",
       "      <td>0.367833</td>\n",
       "      <td>2.367321</td>\n",
       "      <td>1.910351</td>\n",
       "      <td>-2.294297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>5.007194</td>\n",
       "      <td>1.897345</td>\n",
       "      <td>2.955102</td>\n",
       "      <td>-1.099629</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>1.934863</td>\n",
       "      <td>1.356323</td>\n",
       "      <td>1.365399</td>\n",
       "      <td>...</td>\n",
       "      <td>1.129000</td>\n",
       "      <td>1.962463</td>\n",
       "      <td>-1.343881</td>\n",
       "      <td>-0.178627</td>\n",
       "      <td>1.101096</td>\n",
       "      <td>-1.629055</td>\n",
       "      <td>0.695523</td>\n",
       "      <td>2.544372</td>\n",
       "      <td>-2.245057</td>\n",
       "      <td>2.913909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>-10.019052</td>\n",
       "      <td>-0.590313</td>\n",
       "      <td>3.175781</td>\n",
       "      <td>0.493654</td>\n",
       "      <td>-1.082617</td>\n",
       "      <td>2.625749</td>\n",
       "      <td>2.779737</td>\n",
       "      <td>1.365399</td>\n",
       "      <td>...</td>\n",
       "      <td>1.129000</td>\n",
       "      <td>1.962463</td>\n",
       "      <td>-1.343881</td>\n",
       "      <td>-0.178627</td>\n",
       "      <td>1.101096</td>\n",
       "      <td>-1.629055</td>\n",
       "      <td>0.695523</td>\n",
       "      <td>2.544372</td>\n",
       "      <td>-2.245057</td>\n",
       "      <td>2.913909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABMD</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>13.263002</td>\n",
       "      <td>3.277295</td>\n",
       "      <td>4.150829</td>\n",
       "      <td>1.927447</td>\n",
       "      <td>8.483528</td>\n",
       "      <td>4.566464</td>\n",
       "      <td>6.311604</td>\n",
       "      <td>0.906423</td>\n",
       "      <td>...</td>\n",
       "      <td>1.678670</td>\n",
       "      <td>4.287823</td>\n",
       "      <td>-2.810915</td>\n",
       "      <td>5.212298</td>\n",
       "      <td>2.249722</td>\n",
       "      <td>-8.871266</td>\n",
       "      <td>-2.243599</td>\n",
       "      <td>7.322323</td>\n",
       "      <td>15.023372</td>\n",
       "      <td>-1.298750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>9.218294</td>\n",
       "      <td>-0.520528</td>\n",
       "      <td>2.364408</td>\n",
       "      <td>0.980228</td>\n",
       "      <td>1.074049</td>\n",
       "      <td>1.434426</td>\n",
       "      <td>1.451403</td>\n",
       "      <td>1.982922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274953</td>\n",
       "      <td>2.267602</td>\n",
       "      <td>0.013521</td>\n",
       "      <td>-0.075716</td>\n",
       "      <td>2.022104</td>\n",
       "      <td>-2.275141</td>\n",
       "      <td>9.495909</td>\n",
       "      <td>7.322323</td>\n",
       "      <td>15.023372</td>\n",
       "      <td>-1.298750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol             gics_sector       2019      2018      2017      2016  \\\n",
       "0    MMM             Industrials   4.896570 -1.009762  1.972439  1.577829   \n",
       "1    ABT             Health Care   5.007194  1.897345  2.955102 -1.099629   \n",
       "2   ABBV             Health Care -10.019052 -0.590313  3.175781  0.493654   \n",
       "3   ABMD             Health Care  13.263002  3.277295  4.150829  1.927447   \n",
       "4    ACN  Information Technology   9.218294 -0.520528  2.364408  0.980228   \n",
       "\n",
       "       2015      2014      2013      2012    ...         2007      2006  \\\n",
       "0 -0.644188  2.099564  3.691199  0.980436    ...     0.791992  0.244259   \n",
       "1  0.000240  1.934863  1.356323  1.365399    ...     1.129000  1.962463   \n",
       "2 -1.082617  2.625749  2.779737  1.365399    ...     1.129000  1.962463   \n",
       "3  8.483528  4.566464  6.311604  0.906423    ...     1.678670  4.287823   \n",
       "4  1.074049  1.434426  1.451403  1.982922    ...     0.274953  2.267602   \n",
       "\n",
       "       2005      2004      2003      2002      2001      2000       1999  \\\n",
       "0 -0.399397  0.009860 -1.682022  0.100353  0.367833  2.367321   1.910351   \n",
       "1 -1.343881 -0.178627  1.101096 -1.629055  0.695523  2.544372  -2.245057   \n",
       "2 -1.343881 -0.178627  1.101096 -1.629055  0.695523  2.544372  -2.245057   \n",
       "3 -2.810915  5.212298  2.249722 -8.871266 -2.243599  7.322323  15.023372   \n",
       "4  0.013521 -0.075716  2.022104 -2.275141  9.495909  7.322323  15.023372   \n",
       "\n",
       "       1998  \n",
       "0 -2.294297  \n",
       "1  2.913909  \n",
       "2  2.913909  \n",
       "3 -1.298750  \n",
       "4 -1.298750  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = final_df1.columns.tolist()\n",
    "cols = [cols[0],cols[-1]]+cols[1:-1]\n",
    "final_df = final_df.reindex(columns=cols)\n",
    "final_df = final_df.fillna(0)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_sql(name='stock_yony_return', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
